import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime
from sklearn.metrics.pairwise import cosine_similarity
import time
import json

# Local imports
from services.blocks.file_processor import doc_file
from services.blocks.embedding_engine import load_encoder
from services.blocks.html_generator import load_template, create_html_block, create_interactive_html_block

# âœ… Sá»¬A: Import Ä‘áº§y Ä‘á»§ tá»« rag_orchestrator
from services.blocks.rag_orchestrator import (
    analyze_document_streamlit, 
    compute_similarity_with_excel, 
    store_history, 
    init_knowledge_universe, 
    create_personal_rag, 
    tai_lich_su,
    get_translation_orchestrator  # âœ… HÃ m nÃ y cÃ³ á»Ÿ dÃ²ng 356 trong rag_orchestrator.py
)

# KG module cho upgrade
from services.blocks import knowledge_graph_v2 as kg_module

# Core engines
from ai_core import AI_Core
from voice_block import Voice_Engine
from prompts import DEBATE_PERSONAS, BOOK_ANALYSIS_PROMPT
from services.blocks import knowledge_graph_v2 as kg_module

# Optional supabase import (don't fail app if missing)
try:
    from supabase import create_client, Client
except ImportError:
    pass

# TRANSLATIONS / UI TEXT
TRANS = {
    "vi": {
        "lang_select": "NgÃ´n ngá»¯ / Language / è¯­è¨€",
        "tab1": "ğŸ“š PhÃ¢n TÃ­ch SÃ¡ch",
        "tab2": "âœï¸ Dá»‹ch Giáº£",
        "tab3": "ğŸ—£ï¸ Tranh Biá»‡n",
        "tab4": "ğŸ™ï¸ PhÃ²ng Thu AI",
        "tab5": "â³ Nháº­t KÃ½",
        "t1_header": "Trá»£ lÃ½ NghiÃªn cá»©u & Knowledge Graph",
        "t1_up_excel": "1. Káº¿t ná»‘i Kho SÃ¡ch (Excel)",
        "t1_up_doc": "2. TÃ i liá»‡u má»›i (PDF/Docx)",
        "t1_btn": "ğŸš€ PHÃ‚N TÃCH NGAY",
        "t1_analyzing": "Äang phÃ¢n tÃ­ch {name}...",
        "t1_connect_ok": "âœ… ÄÃ£ káº¿t ná»‘i {n} cuá»‘n sÃ¡ch.",
        "t1_graph_title": "ğŸª VÅ© trá»¥ SÃ¡ch",
        "t1_seed_books": "âœ… ÄÃ£ táº£i {n} sÃ¡ch tinh hoa vÃ o Knowledge Graph (18 sÃ¡ch bao trÃ¹m 4 táº§ng triáº¿t há»c)",
        "t2_header": "Dá»‹ch Thuáº­t Äa Chiá»u",
        "t2_input": "Nháº­p vÄƒn báº£n cáº§n dá»‹ch:",
        "t2_target": "Dá»‹ch sang:",
        "t2_style": "Phong cÃ¡ch:",
        "t2_btn": "âœï¸ Dá»‹ch Ngay",
        "t3_header": "Äáº¥u TrÆ°á»ng TÆ° Duy",
        "t3_persona_label": "Chá»n Äá»‘i Thá»§:",
        "t3_input": "Nháº­p chá»§ Ä‘á» tranh luáº­n...",
        "t3_clear": "ğŸ—‘ï¸ XÃ³a Chat",
        "t4_header": "ğŸ™ï¸ PhÃ²ng Thu AI Äa NgÃ´n Ngá»¯",
        "t4_voice": "Chá»n Giá»ng:",
        "t4_speed": "Tá»‘c Ä‘á»™:",
        "t4_btn": "ğŸ”Š Táº O AUDIO",
        "t5_header": "Nháº­t KÃ½ & Lá»‹ch Sá»­",
        "t5_refresh": "ğŸ”„ Táº£i láº¡i Lá»‹ch sá»­",
        "t5_empty": "ChÆ°a cÃ³ dá»¯ liá»‡u lá»‹ch sá»­.",
    },
    "en": {
        "lang_select": "Language",
        "tab1": "ğŸ“š Book Analysis",
        "tab2": "âœï¸ Translator",
        "tab3": "ğŸ—£ï¸ Debater",
        "tab4": "ğŸ™ï¸ AI Studio",
        "tab5": "â³ History",
        "t1_header": "Research Assistant & Knowledge Graph",
        "t1_up_excel": "1. Connect Book Database (Excel)",
        "t1_up_doc": "2. New Documents (PDF/Docx)",
        "t1_btn": "ğŸš€ ANALYZE NOW",
        "t1_analyzing": "Analyzing {name}...",
        "t1_connect_ok": "âœ… Connected {n} books.",
        "t1_graph_title": "ğŸª Book Universe",
        "t1_seed_books": "âœ… Loaded {n} foundational books into Knowledge Graph (18 books covering 4 philosophy layers)",
        "t2_header": "Multidimensional Translator",
        "t2_input": "Enter text to translate:",
        "t2_target": "Translate to:",
        "t2_style": "Style:",
        "t2_btn": "âœï¸ Translate",
        "t3_header": "Thinking Arena",
        "t3_persona_label": "Choose Opponent:",
        "t3_input": "Enter debate topic...",
        "t3_clear": "ğŸ—‘ï¸ Clear Chat",
        "t4_header": "ğŸ™ï¸ Multilingual AI Studio",
        "t4_voice": "Select Voice:",
        "t4_speed": "Speed:",
        "t4_btn": "ğŸ”Š GENERATE AUDIO",
        "t5_header": "Logs & History",
        "t5_refresh": "ğŸ”„ Refresh History",
        "t5_empty": "No history data found.",
    },
    "zh": {
        "lang_select": "è¯­è¨€",
        "tab1": "ğŸ“š ä¹¦ç±åˆ†æ",
        "tab2": "âœï¸ ç¿»è¯‘ä¸“å®¶",
        "tab3": "ğŸ—£ï¸ è¾©è®ºåœº",
        "tab4": "ğŸ™ï¸ AI å½•éŸ³å®¤",
        "tab5": "â³ å†å²è®°å½•",
        "t1_header": "ç ”ç©¶åŠ©æ‰‹ & çŸ¥è¯†å›¾è°±",
        "t1_up_excel": "1. è¿æ¥ä¹¦åº“ (Excel)",
        "t1_up_doc": "2. ä¸Šä¼ æ–°æ–‡æ¡£ (PDF/Docx)",
        "t1_btn": "ğŸš€ ç«‹å³åˆ†æ",
        "t1_analyzing": "æ­£åœ¨åˆ†æ {name}...",
        "t1_connect_ok": "âœ… å·²è¿æ¥ {n} æœ¬ä¹¦ã€‚",
        "t1_graph_title": "ğŸª ä¹¦ç±å®‡å®™",
        "t1_seed_books": "âœ… å·²åŠ è½½ {n} æœ¬ç²¾åä¹¦ç±åˆ°çŸ¥è¯†å›¾è°± (18æœ¬ä¹¦è¦†ç›–4å±‚å“²å­¦)",
        "t2_header": "å¤šç»´ç¿»è¯‘",
        "t2_input": "è¾“å…¥æ–‡æœ¬:",
        "t2_target": "ç¿»è¯‘æˆ:",
        "t2_style": "é£æ ¼:",
        "t2_btn": "âœï¸ ç¿»è¯‘",
        "t3_header": "æ€ç»´ç«æŠ€åœº",
        "t3_persona_label": "é€‰æ‹©å¯¹æ‰‹:",
        "t3_input": "è¾“å…¥è¾©è®ºä¸»é¢˜...",
        "t3_clear": "ğŸ—‘ï¸ æ¸…é™¤èŠå¤©",
        "t4_header": "ğŸ™ï¸ AI å¤šè¯­è¨€å½•éŸ³å®¤",
        "t4_voice": "é€‰æ‹©å£°éŸ³:",
        "t4_speed": "è¯­é€Ÿ:",
        "t4_btn": "ğŸ”Š ç”ŸæˆéŸ³é¢‘",
        "t5_header": "æ—¥å¿— & å†å²",
        "t5_refresh": "ğŸ”„ åˆ·æ–°å†å²",
        "t5_empty": "æš‚æ— å†å²æ•°æ®ã€‚",
    }
}

def T(key):
    lang = st.session_state.get('weaver_lang', 'vi')
    return TRANS.get(lang, TRANS['vi']).get(key, key)

@st.cache_resource
def load_models():
    try:
        model = load_encoder()
        return model
    except Exception:
        return None

def check_model_available():
    model = load_models()
    if model is None:
        st.warning("âš ï¸ Chá»©c nÄƒng Knowledge Graph táº¡m thá»i khÃ´ng kháº£ dá»¥ng (thiáº¿u RAM)")
        return False
    return True

def doc_file_safe(uploaded_file):
    return doc_file(uploaded_file)

# âœ… Sá»¬A: Helper Ä‘á»ƒ init KnowledgeUniverse vá»›i sÃ¡ch tinh hoa + Excel upgrade
@st.cache_resource
def get_knowledge_universe(excel_file=None):
    """Khá»Ÿi táº¡o Knowledge Graph vá»›i sÃ¡ch tinh hoa (18 sÃ¡ch) + optional Excel upgrade"""
    try:
        # BÆ¯á»šC 1: Táº¡o KG cÆ¡ báº£n (Ä‘Ã£ cÃ³ 18 sÃ¡ch tinh hoa tá»« knowledge_graph_v2.py)
        ku = init_knowledge_universe()
        if not ku:
            st.warning("âš ï¸ KhÃ´ng thá»ƒ khá»Ÿi táº¡o Knowledge Graph")
            return None
        
        # BÆ¯á»šC 2: Náº¿u cÃ³ Excel, upgrade thÃªm sÃ¡ch tá»« Excel
        if excel_file:
            try:
                # Äá»c Excel Ä‘á»ƒ láº¥y danh sÃ¡ch sÃ¡ch
                df_excel = pd.read_excel(excel_file).dropna(subset=["TÃªn sÃ¡ch"])
                st.success(f"âœ… ÄÃ£ káº¿t ná»‘i {len(df_excel)} cuá»‘n sÃ¡ch tá»« Excel")
                
                # Upgrade KG vá»›i sÃ¡ch tá»« Excel
                ku = kg_module.upgrade_existing_database(excel_file, ku)
                
                # Hiá»ƒn thá»‹ thÃ´ng bÃ¡o thÃ nh cÃ´ng
                total_books = len(ku.graph.nodes)
                st.success(f"âœ… ÄÃ£ táº£i {total_books} sÃ¡ch vÃ o Knowledge Graph (bao gá»“m 18 sÃ¡ch tinh hoa + {len(df_excel)} tá»« Excel)")
                
            except Exception as e:
                st.warning(f"âš ï¸ KhÃ´ng thá»ƒ upgrade tá»« Excel: {e}")
        else:
            # Chá»‰ cÃ³ sÃ¡ch tinh hoa
            total_books = len(ku.graph.nodes)
            st.info(f"ğŸ“š ÄÃ£ táº£i {total_books} sÃ¡ch tinh hoa vÃ o Knowledge Graph (18 sÃ¡ch bao trÃ¹m 4 táº§ng triáº¿t há»c)")
        
        return ku
        
    except Exception as e:
        st.error(f"âŒ Lá»—i khá»Ÿi táº¡o Knowledge Graph: {e}")
        return None

# --- RUN ---
def run():
    ai = AI_Core()
    voice = Voice_Engine()

    # âœ… THAY Äá»”I: Khá»Ÿi táº¡o KG vá»›i thÃ´ng bÃ¡o rÃµ rÃ ng vá» sÃ¡ch tinh hoa
    knowledge_universe = get_knowledge_universe()

    with st.sidebar:
        st.markdown("---")
        lang_choice = st.selectbox("ğŸŒ " + TRANS['vi']['lang_select'], ["Tiáº¿ng Viá»‡t", "English", "ä¸­æ–‡"], key="weaver_lang_selector")
        if lang_choice == "Tiáº¿ng Viá»‡t":
            st.session_state.weaver_lang = 'vi'
        elif lang_choice == "English":
            st.session_state.weaver_lang = 'en'
        else:
            st.session_state.weaver_lang = 'zh'

    st.header(f"ğŸ§  The Cognitive Weaver")
    
    # âœ… HIá»‚N THá»Š TRáº NG THÃI KG (Má»šI)
    if knowledge_universe:
        summary = knowledge_universe.get_episteme_summary()
        col1, col2, col3, col4 = st.columns(4)
        for layer, data in summary.items():
            with eval(f"col{1+list(summary.keys()).index(layer)}"):
                st.metric(layer[:15], f"{data['count']} sÃ¡ch", delta=f"{len(data['recent'])} recent")

    tab1, tab2, tab3, tab4, tab5 = st.tabs([T("tab1"), T("tab2"), T("tab3"), T("tab4"), T("tab5")])

    # TAB 1: RAG (Cáº¢I TIáº¾N vá»›i KG integration)
    with tab1:
        st.header(T("t1_header"))
        with st.container():
            c1, c2, c3 = st.columns([1, 1, 1])
            with c1:
                file_excel = st.file_uploader(T("t1_up_excel"), type="xlsx", key="t1_excel")
            with c2:
                uploaded_files = st.file_uploader(T("t1_up_doc"), type=["pdf", "docx", "txt", "md", "html"], accept_multiple_files=True, key="t1_files")
            with c3:
                st.write("")
                st.write("")
                btn_run = st.button(T("t1_btn"), type="primary", use_container_width=True)

        # âœ… RELOAD KG náº¿u cÃ³ Excel má»›i
        if file_excel and btn_run:
            knowledge_universe = get_knowledge_universe(file_excel)

        if btn_run and uploaded_files:
            vec = load_encoder()
            has_db_excel = bool(file_excel)

            for f in uploaded_files:
                text = doc_file_safe(f)
                if not text:
                    st.warning(f"âš ï¸ KhÃ´ng Ä‘á»c Ä‘Æ°á»£c file {f.name}")
                    continue

                link = ""
                if has_db_excel and vec is not None:
                    try:
                        matches = compute_similarity_with_excel(text, pd.read_excel(file_excel).dropna(subset=["TÃªn sÃ¡ch"]), vec)
                        if matches:
                            link = "\n".join([f"- {m[0]} ({m[1]*100:.0f}%)" for m in matches])
                    except Exception as e:
                        st.warning(f"KhÃ´ng thá»ƒ tÃ­nh similarity: {e}")

                # âœ… TÃŒM SÃCH LIÃŠN QUAN Tá»ª KG (Æ°u tiÃªn)
                related = []
                if knowledge_universe:
                    try:
                        related = knowledge_universe.find_related_books(text[:2000], top_k=5)
                    except Exception as e:
                        st.warning(f"Lá»—i KG search: {e}")

                with st.spinner(T("t1_analyzing").format(name=f.name)):
                    res = analyze_document_streamlit(f.name, text, user_lang=st.session_state.get('weaver_lang', 'vi'))
                    if res and "Lá»—i" not in res:
                        st.markdown(f"### ğŸ“„ {f.name}")
                        if link:
                            st.markdown("**ğŸ”— SÃ¡ch tÆ°Æ¡ng tá»± tá»« Excel:**")
                            st.markdown(link)
                        if related:
                            st.markdown("**ğŸª SÃ¡ch liÃªn quan tá»« Knowledge Graph (18 sÃ¡ch tinh hoa):**")
                            for node_id, title, score, explanation in related:
                                fp = knowledge_universe.graph.nodes[node_id].get("first_principles", "")
                                st.markdown(f"- **{title}** ({score:.2f}) â€” {explanation}" + (f"\n  *First Principles:* {fp}" if fp else ""))
                        st.markdown(res)
                        st.markdown("---")
                        store_history("PhÃ¢n TÃ­ch SÃ¡ch", f.name, res)
                    else:
                        st.error(f"âŒ KhÃ´ng thá»ƒ phÃ¢n tÃ­ch file {f.name}: {res}")

        # Graph visualization (cáº£i tiáº¿n vá»›i KG export)
        if knowledge_universe:
            with st.expander(T("t1_graph_title"), expanded=False):
                try:
                    nodes, edges = knowledge_universe.export_for_visualization()
                    if nodes:
                        from streamlit_agraph import agraph, Node, Edge, Config
                        config = Config(width=1000, height=600, directed=True, physics=True)
                        agraph(nodes[:50], edges[:100], config)  # Limit Ä‘á»ƒ trÃ¡nh lag
                except Exception as e:
                    st.info("ğŸ“Š Graph visualization táº¡m thá»i khÃ´ng kháº£ dá»¥ng.")
        elif file_excel:
            # Fallback Excel graph (giá»¯ nguyÃªn logic cÅ©)
            try:
                if "df_viz" not in st.session_state:
                    st.session_state.df_viz = pd.read_excel(file_excel).dropna(subset=["TÃªn sÃ¡ch"])
                # ... (code graph Excel cÅ© giá»¯ nguyÃªn)
            except:
                pass

    
    # TAB 2: Dá»‹ch Thuáº­t Äa Chiá»u (NÃ‚NG Cáº¤P - dÃ¹ng TranslationOrchestrator)
    with tab2:
        st.subheader(T("t2_header"))
        st.markdown("**Dá»‹ch vÄƒn báº£n Ä‘a ngÃ´n ngá»¯ vá»›i phong cÃ¡ch chuyÃªn nghiá»‡p, há»— trá»£ interactive (tiáº¿ng Trung) vÃ  táº£i file HTML.**")

        # Input text
        input_text = st.text_area("Nháº­p vÄƒn báº£n cáº§n dá»‹ch:", height=200, key="translator_input")

        col1, col2, col3 = st.columns(3)
        with col1:
            source_lang = st.selectbox(
                "NgÃ´n ngá»¯ nguá»“n:",
                ["Chinese", "English", "Vietnamese", "French", "Japanese", "Korean"],
                index=0
            )
        with col2:
            target_lang = st.selectbox(
                "NgÃ´n ngá»¯ Ä‘Ã­ch:",
                ["Vietnamese", "English", "Chinese", "French", "Japanese", "Korean"],
                index=0
            )
        with col3:
            mode = st.radio("Cháº¿ Ä‘á»™ dá»‹ch:", ["Standard (HTML Ä‘áº¹p)", "Interactive (chá»‰ tiáº¿ng Trung â†’ Viá»‡t)"], horizontal=True)

        include_english = st.checkbox("ThÃªm báº£n dá»‹ch tiáº¿ng Anh lÃ m tham chiáº¿u (náº¿u cáº§n)", value=True)

        if st.button("ğŸš€ Dá»‹ch ngay", type="primary", use_container_width=True):
            if not input_text.strip():
                st.warning("Vui lÃ²ng nháº­p vÄƒn báº£n cáº§n dá»‹ch.")
            else:
                # Láº¥y orchestrator
                orchestrator = get_translation_orchestrator()
                if not orchestrator:
                    st.error("âš ï¸ KhÃ´ng táº£i Ä‘Æ°á»£c bá»™ dá»‹ch. Kiá»ƒm tra translator.py vÃ  API key.")
                else:
                    progress_bar = st.progress(0)
                    status_text = st.empty()

                    def update_progress(value):
                        progress_bar.progress(value)
                        status_text.text(f"Äang dá»‹ch... {int(value*100)}%")

                    try:
                        if mode == "Interactive (chá»‰ tiáº¿ng Trung â†’ Viá»‡t)":
                            if source_lang != "Chinese":
                                st.error("Interactive mode chá»‰ há»— trá»£ nguá»“n tiáº¿ng Trung.")
                            else:
                                status_text.text("Äang xá»­ lÃ½ interactive translation...")
                                html_output = orchestrator.translate_interactive(
                                    input_text,
                                    source_lang="Chinese",
                                    target_lang=target_lang
                                )
                        else:
                            status_text.text("Äang dá»‹ch vÃ  táº¡o HTML...")
                            html_output = orchestrator.translate_document(
                                input_text,
                                source_lang=source_lang,
                                target_lang=target_lang,
                                include_english=include_english and target_lang != "English",
                                progress_callback=update_progress
                            )

                        # ThÃ nh cÃ´ng
                        progress_bar.progress(1.0)
                        status_text.success("âœ… HoÃ n thÃ nh!")

                        # NÃºt táº£i HTML
                        st.download_button(
                            label="ğŸ“¥ Táº£i file HTML káº¿t quáº£",
                            data=html_output.encode('utf-8'),
                            file_name=f"translation_{source_lang}_to_{target_lang}.html",
                            mime="text/html"
                        )

                        # Preview
                        with st.expander("ğŸ‘€ Xem trÆ°á»›c káº¿t quáº£", expanded=True):
                            st.components.v1.html(html_output, height=800, scrolling=True)

                        # LÆ°u lá»‹ch sá»­
                        store_history(
                            "Dá»‹ch Thuáº­t",
                            f"{source_lang} â†’ {target_lang} ({mode})",
                            input_text[:300]
                        )

                    except Exception as e:
                        progress_bar.empty()
                        status_text.empty()
                        st.error(f"âŒ Lá»—i trong quÃ¡ trÃ¬nh dá»‹ch: {str(e)}")
                        with st.expander("Chi tiáº¿t lá»—i"):
                            st.exception(e)

    # TAB 3: Äáº¥u trÆ°á»ng
    with tab3:
        st.subheader(T("t3_header"))
        mode = st.radio("Mode:", ["ğŸ‘¤ Solo", "âš”ï¸ Multi-Agent"], horizontal=True, key="w_t3_mode")
        if "weaver_chat" not in st.session_state:
            st.session_state.weaver_chat = []

        if mode == "ğŸ‘¤ Solo":
            c1, c2 = st.columns([3, 1])
            with c1:
                persona = st.selectbox(T("t3_persona_label"), list(DEBATE_PERSONAS.keys()), key="w_t3_solo_p")
            with c2:
                if st.button(T("t3_clear"), key="w_t3_clr"):
                    st.session_state.weaver_chat = []
                    st.rerun()
            for msg in st.session_state.weaver_chat:
                st.chat_message(msg["role"]).write(msg["content"])
            if prompt := st.chat_input(T("t3_input")):
                st.chat_message("user").write(prompt)
                st.session_state.weaver_chat.append({"role": "user", "content": prompt})
                recent_history = st.session_state.weaver_chat[-10:]
                context_text = "\n".join([f"{m['role'].upper()}: {m['content']}" for m in recent_history])
                full_prompt = f"Lá»ŠCH Sá»¬:\n{context_text}\n\nNHIá»†M Vá»¤: Tráº£ lá»i cÃ¢u há»i má»›i nháº¥t cá»§a USER."
                with st.chat_message("assistant"):
                    with st.spinner("..."):
                        res = ai.generate(full_prompt, model_type="flash", system_instruction=DEBATE_PERSONAS[persona])
                        if res:
                            st.write(res)
                            st.session_state.weaver_chat.append({"role": "assistant", "content": res})
                            store_history("Tranh Biá»‡n Solo", f"{persona} - {prompt[:50]}...", f"Q: {prompt}\nA: {res}")
        else:
            participants = st.multiselect("Chá»n Há»™i Äá»“ng:", list(DEBATE_PERSONAS.keys()),
                                          default=[list(DEBATE_PERSONAS.keys())[0], list(DEBATE_PERSONAS.keys())[1]],
                                          max_selections=3)
            topic = st.text_input("Chá»§ Ä‘á»:", key="w_t3_topic")
            if st.button("ğŸ”¥ KHAI CHIáº¾N", disabled=(len(participants) < 2 or not topic)):
                st.session_state.weaver_chat = []
                start_msg = f"ğŸ“¢ **CHá»¦ Tá»ŒA:** Khai máº¡c tranh luáº­n vá»: *'{topic}'*"
                st.session_state.weaver_chat.append({"role": "system", "content": start_msg})
                st.info(start_msg)
                full_transcript = [start_msg]

                MAX_DEBATE_TIME = 600
                start_time = time.time()

                with st.status("ğŸ”¥ Cuá»™c chiáº¿n Ä‘ang diá»…n ra (3 vÃ²ng)...") as status:
                    try:
                        for round_num in range(1, 4):
                            if time.time() - start_time > MAX_DEBATE_TIME:
                                st.warning("â° Háº¿t giá»! Cuá»™c tranh luáº­n káº¿t thÃºc sá»›m.")
                                break

                            status.update(label=f"ğŸ”„ VÃ²ng {round_num}/3 Ä‘ang diá»…n ra...")

                            for i, p_name in enumerate(participants):
                                if time.time() - start_time > MAX_DEBATE_TIME:
                                    break

                                context_str = topic
                                if len(st.session_state.weaver_chat) > 1:
                                    recent_msgs = st.session_state.weaver_chat[-4:]
                                    context_str = "\n".join([f"{m['role']}: {m['content']}" for m in recent_msgs])

                                length_instruction = " (Báº®T BUá»˜C: Tráº£ lá»i ngáº¯n gá»n khoáº£ng 150-200 tá»«. Äi tháº³ng vÃ o trá»ng tÃ¢m, khÃ´ng lan man.)"

                                if round_num == 1:
                                    p_prompt = f"CHá»¦ Äá»€: {topic}\nNHIá»†M Vá»¤ (VÃ²ng 1 - Má»Ÿ Ä‘áº§u): NÃªu quan Ä‘iá»ƒm chÃ­nh vÃ  2-3 lÃ½ láº½. {length_instruction}"
                                else:
                                    p_prompt = f"CHá»¦ Äá»€: {topic}\nBá»I Cáº¢NH Má»šI NHáº¤T:\n{context_str}\n\nNHIá»†M Vá»¤ (VÃ²ng {round_num} - Pháº£n biá»‡n): Pháº£n biá»‡n sáº¯c bÃ©n quan Ä‘iá»ƒm Ä‘á»‘i thá»§ vÃ  cá»§ng cá»‘ láº­p trÆ°á»ng cá»§a mÃ¬nh. {length_instruction}"

                                try:
                                    res = ai.generate(
                                        p_prompt,
                                        model_type="pro",
                                        system_instruction=DEBATE_PERSONAS[p_name]
                                    )

                                    if res:
                                        clean_res = res.replace(f"{p_name}:", "").strip()
                                        clean_res = clean_res.replace(f"**{p_name}:**", "").strip()
                                        icons = {"Káº» Pháº£n Biá»‡n": "ğŸ˜ˆ", "Shushu": "ğŸ©", "Pháº­t Tá»•": "ğŸ™", "Socrates": "ğŸ›ï¸"}
                                        icon = icons.get(p_name, "ğŸ¤–")
                                        content_fmt = f"### {icon} {p_name}\n\n{clean_res}"
                                        st.session_state.weaver_chat.append({"role": "assistant", "content": content_fmt})
                                        full_transcript.append(content_fmt)
                                        with st.chat_message("assistant", avatar=icon):
                                            st.markdown(content_fmt)
                                        time.sleep(3)
                                except Exception as e:
                                    st.error(f"Lá»—i khi gá»i AI cho {p_name}: {e}")
                                    continue
                        status.update(label="âœ… Tranh luáº­n káº¿t thÃºc!", state="complete")
                    except Exception as e:
                        st.error(f"Lá»—i trong quÃ¡ trÃ¬nh tranh luáº­n: {e}")

                full_log = "\n\n".join(full_transcript)
                store_history("Há»™i Äá»“ng Tranh Biá»‡n", f"Chá»§ Ä‘á»: {topic}", full_log)

    # TAB 4: VOICE
    with tab4:
        st.subheader(T("t4_header"))
        
        # 1. Chá»n Giá»ng (Láº¥y tá»« Voice Engine)
        if voice and hasattr(voice, 'VOICE_OPTIONS'):
            voice_opts = list(voice.VOICE_OPTIONS.keys())
            selected_voice = st.selectbox(T("t4_voice"), voice_opts, index=0)
        else:
            selected_voice = None
            st.warning("âš ï¸ ChÆ°a táº£i Ä‘Æ°á»£c module giá»ng nÃ³i.")

        # 2. Chá»n Tá»‘c Ä‘á»™
        speed = st.slider(T("t4_speed"), -50, 50, 0, format="%d%%")

        # 3. Nháº­p vÄƒn báº£n
        inp_v = st.text_area("Text:", height=150)
        
        if st.button(T("t4_btn")) and inp_v:
            with st.spinner("Äang táº¡o Ã¢m thanh..."):
                # Truyá»n giá»ng vÃ  tá»‘c Ä‘á»™ vÃ o hÃ m speak
                path = voice.speak(inp_v, voice_key=selected_voice, speed=speed)
                if path: 
                    st.audio(path)

    # TAB 5: NHáº¬T KÃ (CÃ“ PHáº¦N BAYES)
    with tab5:
        st.subheader("â³ Nháº­t KÃ½ & Pháº£n Chiáº¿u TÆ° Duy")
        if st.button("ğŸ”„ Táº£i láº¡i", key="w_t5_refresh"):
            st.session_state.history_cloud = tai_lich_su()
            st.rerun()

        data = st.session_state.get("history_cloud", tai_lich_su())

        if data:
            df_h = pd.DataFrame(data)

            if "SentimentScore" in df_h.columns:
                try:
                    df_h["score"] = pd.to_numeric(df_h["SentimentScore"], errors='coerce').fillna(0)
                    import plotly.express as px
                    fig = px.line(df_h, x="Time", y="score", markers=True, color_discrete_sequence=["#76FF03"])
                    st.plotly_chart(fig, use_container_width=True)
                except:
                    pass

            with st.expander("ğŸ”® PhÃ¢n tÃ­ch TÆ° duy theo xÃ¡c suáº¥t Bayes (E.T. Jaynes)", expanded=False):
                st.info("AI sáº½ coi Lá»‹ch sá»­ hoáº¡t Ä‘á»™ng cá»§a chá»‹ lÃ  'Dá»¯ liá»‡u quan sÃ¡t' (Evidence) Ä‘á»ƒ suy luáº­n ra 'HÃ m má»¥c tiÃªu' (Objective Function) vÃ  sá»± dá»‹ch chuyá»ƒn niá»m tin cá»§a chá»‹.")

                if st.button("ğŸ§  Cháº¡y MÃ´ hÃ¬nh Bayes ngay"):
                    with st.spinner("Äang tÃ­nh toÃ¡n xÃ¡c suáº¥t háº­u nghiá»‡m (Posterior)..."):
                        recent_logs = df_h.tail(10).to_dict(orient="records")
                        logs_text = json.dumps(recent_logs, ensure_ascii=False)

                        bayes_prompt = f"""
                        ÄÃ³ng vai má»™t nhÃ  khoa há»c tÆ° duy theo trÆ°á»ng phÃ¡i E.T. Jaynes (sÃ¡ch 'Probability Theory: The Logic of Science').

                        Dá»® LIá»†U QUAN SÃT (EVIDENCE):
                        ÄÃ¢y lÃ  nháº­t kÃ½ hoáº¡t Ä‘á»™ng cá»§a tÃ´i:
                        {logs_text}

                        NHIá»†M Vá»¤:
                        HÃ£y phÃ¢n tÃ­ch chuá»—i hÃ nh Ä‘á»™ng nÃ y nhÆ° má»™t bÃ i toÃ¡n suy luáº­n Bayes.
                        1. **XÃ¡c Ä‘á»‹nh Priors (Niá»m tin tiÃªn nghiá»‡m):** Dá»±a trÃªn cÃ¡c hÃ nh Ä‘á»™ng Ä‘áº§u, tÃ´i Ä‘ang quan tÃ¢m/tin tÆ°á»Ÿng Ä‘iá»u gÃ¬?
                        2. **Cáº­p nháº­t Likelihood (Kháº£ nÄƒng):** CÃ¡c hÃ nh Ä‘á»™ng tiáº¿p theo cá»§ng cá»‘ hay lÃ m yáº¿u Ä‘i niá»m tin Ä‘Ã³?
                        3. **Káº¿t luáº­n Posterior (Háº­u nghiá»‡m):** Tráº¡ng thÃ¡i tÆ° duy hiá»‡n táº¡i cá»§a tÃ´i Ä‘ang há»™i tá»¥ vá» Ä‘Ã¢u? CÃ³ mÃ¢u thuáº«n (Inconsistency) nÃ o trong logic hÃ nh Ä‘á»™ng khÃ´ng?

                        Tráº£ lá»i ngáº¯n gá»n, sÃ¢u sáº¯c, dÃ¹ng thuáº­t ngá»¯ xÃ¡c suáº¥t nhÆ°ng dá»… hiá»ƒu.
                        """

                        analysis = ai.generate(bayes_prompt, model_type="pro")
                        st.markdown(analysis)

            st.divider()
            for index, item in df_h.iterrows():
                t = str(item.get('Time', ''))
                tp = str(item.get('Type', ''))
                ti = str(item.get('Title', ''))
                ct = str(item.get('Content', ''))

                icon = "ğŸ“"
                if "Tranh Biá»‡n" in tp:
                    icon = "ğŸ—£ï¸"
                elif "Dá»‹ch" in tp:
                    icon = "âœï¸"

                with st.expander(f"{icon} {t} | {tp} | {ti}"):
                    st.markdown(ct)
        else:
            st.info(T("t5_empty"))
