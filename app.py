import streamlit as st
import google.generativeai as genai
import pandas as pd
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
from pypdf import PdfReader
from docx import Document
from bs4 import BeautifulSoup
import numpy as np
import os
import time
from datetime import datetime

# --- 1. C·∫§U H√åNH TRANG & SESSION STATE (B·ªò NH·ªö) ---
st.set_page_config(page_title="Mai Hanh Super App", layout="wide", page_icon="üíé")

# Kh·ªüi t·∫°o b·ªô nh·ªõ l·ªãch s·ª≠ n·∫øu ch∆∞a c√≥ (Gi·ªëng ChatGPT)
if 'history' not in st.session_state:
    st.session_state.history = []
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []

# --- 2. C·∫§U H√åNH API & MODEL ---
# L·∫•y API Key t·ª´ Secrets (Cloud) ho·∫∑c Sidebar (Local)
if 'GOOGLE_API_KEY' in st.secrets:
    api_key = st.secrets['GOOGLE_API_KEY']
else:
    api_key = st.sidebar.text_input("Nh·∫≠p Google API Key:", type="password")

if not api_key:
    st.warning("‚ö†Ô∏è Vui l√≤ng nh·∫≠p API Key ƒë·ªÉ b·∫Øt ƒë·∫ßu.")
    st.stop()

genai.configure(api_key=api_key)

# C·ªê G·∫ÆNG D√ôNG MODEL M·ªöI NH·∫§T (Th√°ng 12/2025)
try:
    model = genai.GenerativeModel('gemini-2.5-pro') # Gi·∫£ l·∫≠p b·∫£n t∆∞∆°ng lai
except:
    try:
        model = genai.GenerativeModel('gemini-2.5-flash-latest') # B·∫£n ·ªïn ƒë·ªãnh
    except:
        model = genai.GenerativeModel('gemini-2.5-flash') # B·∫£n d·ª± ph√≤ng

# --- 3. C√ÅC H√ÄM X·ª¨ L√ù (BACKEND) ---
@st.cache_resource
def load_models():
    return SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')

def doc_file(uploaded_file):
    if not uploaded_file: return ""
    ext = os.path.splitext(uploaded_file.name)[1].lower()
    try:
        if ext == '.pdf':
            reader = PdfReader(uploaded_file)
            return "\n".join([page.extract_text() for page in reader.pages])
        elif ext == '.docx':
            doc = Document(uploaded_file)
            return "\n".join([p.text for p in doc.paragraphs])
        elif ext in ['.txt', '.md']:
            return str(uploaded_file.read(), "utf-8")
        elif ext in ['.html', '.htm']:
            soup = BeautifulSoup(uploaded_file, 'html.parser')
            return soup.get_text()
    except: return ""
    return ""

def luu_lich_su(loai, tieu_de, noi_dung):
    """H√†m l∆∞u k·∫øt qu·∫£ v√†o b·ªô nh·ªõ t·∫°m"""
    thoi_gian = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    st.session_state.history.append({
        "time": thoi_gian,
        "type": loai,
        "title": tieu_de,
        "content": noi_dung
    })

# --- 4. GIAO DI·ªÜN CH√çNH (TABS) ---
st.title("üíé The Mai Hanh Super-App (AI Ecosystem)")

# T·∫°o c√°c Tab ch·ª©c nƒÉng
tab1, tab2, tab3, tab4 = st.tabs([
    "üìö Ph√¢n T√≠ch S√°ch (Analyzer)", 
    "‚úçÔ∏è D·ªãch Gi·∫£ X·ªãn (Linguist)", 
    "üó£Ô∏è Tranh Bi·ªán (Debater)",
    "aaa L·ªãch S·ª≠ (History)"
])

# ================= TAB 1: PH√ÇN T√çCH S√ÅCH (C≈® + N√ÇNG C·∫§P) =================
with tab1:
    st.header("Tr·ª£ l√Ω Nghi√™n c·ª©u & Li√™n k·∫øt Tri th·ª©c")
    
    col_a, col_b = st.columns([1, 2])
    with col_a:
        file_excel = st.file_uploader("1. K·∫øt n·ªëi Kho S√°ch (Excel)", type="xlsx", key="tab1_excel")
        uploaded_files = st.file_uploader("2. Upload T√†i li·ªáu m·ªõi", type=["pdf","docx","txt","md"], accept_multiple_files=True, key="tab1_files")
        btn_analyze = st.button("üöÄ Ph√¢n T√≠ch Chi·∫øn L∆∞·ª£c", type="primary")

    with col_b:
        if btn_analyze and uploaded_files:
            # Setup Vector
            vec_model = None
            db_vec = None
            df = None
            if file_excel:
                try:
                    df = pd.read_excel(file_excel).dropna(subset=['T√™n s√°ch'])
                    vec_model = load_models()
                    content = [f"{r['T√™n s√°ch']} {r['C·∫¢M NH·∫¨N']}" for i,r in df.iterrows()]
                    db_vec = vec_model.encode(content)
                    st.success(f"‚úÖ ƒê√£ k·∫øt n·ªëi {len(df)} cu·ªën s√°ch c≈©.")
                except: st.error("L·ªói file Excel")

            # X·ª≠ l√Ω t·ª´ng file
            full_report = ""
            progress = st.progress(0)
            
            for i, file_doc in enumerate(uploaded_files):
                text = doc_file(file_doc)
                
                # RAG
                lien_ket = ""
                if file_excel and len(text) > 100:
                    try:
                        query_vec = vec_model.encode([text[:1000]])
                        scores = cosine_similarity(query_vec, db_vec)[0]
                        top = np.argsort(scores)[::-1][:3]
                        for idx in top:
                            if scores[idx] > 0.35:
                                lien_ket += f"- {df.iloc[idx]['T√™n s√°ch']}\n"
                    except: pass
                
                prompt = f"""
                Ph√¢n t√≠ch t√†i li·ªáu: '{file_doc.name}'.
                Li√™n k·∫øt s√°ch c≈©: {lien_ket}
                Y√™u c·∫ßu: T√≥m t·∫Øt, Nh·∫≠n x√©t s√¢u s·∫Øc, Tr√≠ch d·∫´n hay.
                N·ªôi dung: {text}
                """
                res = model.generate_content(prompt)
                
                with st.expander(f"üìÑ K·∫øt qu·∫£: {file_doc.name}", expanded=True):
                    st.markdown(res.text)
                
                full_report += f"=== T√ÄI LI·ªÜU: {file_doc.name} ===\n{res.text}\n\n"
                progress.progress((i+1)/len(uploaded_files))
            
            # T·ªïng h·ª£p
            if len(uploaded_files) > 1:
                with st.spinner("ƒêang t·ªïng h·ª£p chi·∫øn l∆∞·ª£c..."):
                    prompt_syn = f"T·ªïng h·ª£p chi·∫øn l∆∞·ª£c t·ª´ c√°c b√°o c√°o sau:\n{full_report}"
                    res_syn = model.generate_content(prompt_syn)
                    st.success("üèÜ B√ÅO C√ÅO T·ªîNG H·ª¢P")
                    st.markdown(res_syn.text)
                    full_report = f"B√ÅO C√ÅO T·ªîNG H·ª¢P:\n{res_syn.text}\n\n" + full_report
            
            # L∆∞u v√†o l·ªãch s·ª≠
            luu_lich_su("Ph√¢n T√≠ch S√°ch", f"Batch {len(uploaded_files)} files", full_report)

# ================= TAB 2: D·ªäCH GI·∫¢ X·ªäN (M·ªöI) =================
with tab2:
    st.header("D·ªãch Thu·∫≠t & Ph√¢n T√≠ch VƒÉn Phong")
    col_input, col_output = st.columns(2)
    
    with col_input:
        text_to_translate = st.text_area("Nh·∫≠p vƒÉn b·∫£n (Anh/Trung):", height=300)
        style = st.selectbox("Ch·ªçn phong c√°ch d·ªãch:", ["H√†n l√¢m/H·ªçc thu·∫≠t", "VƒÉn h·ªçc/Truy·ªÅn c·∫£m", "ƒê·ªùi th∆∞·ªùng/D·ªÖ hi·ªÉu", "Kinh t·∫ø/Th∆∞∆°ng m·∫°i"])
        btn_translate = st.button("‚úçÔ∏è D·ªãch & Ph√¢n T√≠ch")
    
    with col_output:
        if btn_translate and text_to_translate:
            with st.spinner("ƒêang d·ªãch gi·∫£ l·∫≠p..."):
                prompt = f"""
                B·∫°n l√† D·ªãch gi·∫£ cao c·∫•p. H√£y th·ª±c hi·ªán 2 vi·ªác:
                1. **D·ªãch** ƒëo·∫°n vƒÉn b·∫£n sau sang Ti·∫øng Vi·ªát theo phong c√°ch: **{style}**.
                2. **Ph√¢n t√≠ch t·ª´ v·ª±ng:** Ch·ªçn ra 3 t·ª´/c·ª•m t·ª´ hay nh·∫•t trong b·∫£n g·ªëc, gi·∫£i th√≠ch nghƒ©a s√¢u v√† ng·ªØ c·∫£nh s·ª≠ d·ª•ng.
                
                VƒÉn b·∫£n g·ªëc:
                {text_to_translate}
                """
                res = model.generate_content(prompt)
                st.markdown(res.text)
                luu_lich_su("D·ªãch Thu·∫≠t", f"D·ªãch phong c√°ch {style}", res.text)

# ================= TAB 3: TRANH BI·ªÜN (DEBATER - M·ªöI) =================
with tab3:
    st.header("Luy·ªán T∆∞ Duy & Ph·∫£n Bi·ªán")
    
    # Hi·ªÉn th·ªã l·ªãch s·ª≠ chat
    for message in st.session_state.chat_history:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # Input chat
    if user_query := st.chat_input("Nh·∫≠p ch·ªß ƒë·ªÅ mu·ªën tranh lu·∫≠n (VD: AI c√≥ thay th·∫ø con ng∆∞·ªùi?)..."):
        # Hi·ªÉn th·ªã c√¢u h·ªèi c·ªßa user
        st.chat_message("user").markdown(user_query)
        st.session_state.chat_history.append({"role": "user", "content": user_query})

        # AI tr·∫£ l·ªùi
        with st.chat_message("assistant"):
            with st.spinner("ƒê·ªëi th·ªß ƒëang suy nghƒ©..."):
                # G·ª≠i k√®m l·ªãch s·ª≠ chat ƒë·ªÉ n√≥ nh·ªõ ng·ªØ c·∫£nh
                history_context = "\n".join([f"{m['role']}: {m['content']}" for m in st.session_state.chat_history[-5:]])
                
                prompt = f"""
                B·∫°n l√† m·ªôt Gi√°o s∆∞/Tri·∫øt gia ph·∫£n bi·ªán kh√≥ t√≠nh.
                Nhi·ªám v·ª•: Tranh lu·∫≠n v·ªõi ng∆∞·ªùi d√πng v·ªÅ ch·ªß ƒë·ªÅ n√†y ƒë·ªÉ gi√∫p h·ªç r√®n luy·ªán t∆∞ duy.
                
                L·ªãch s·ª≠ cu·ªôc tr√≤ chuy·ªán:
                {history_context}
                
                Ng∆∞·ªùi d√πng v·ª´a n√≥i: "{user_query}"
                
                H√£y ph·∫£n b√°c l·∫°i, ho·∫∑c ƒë·∫∑t c√¢u h·ªèi s√¢u s·∫Øc ƒë·ªÉ ng∆∞·ªùi d√πng ph·∫£i suy nghƒ© l·∫°i quan ƒëi·ªÉm c·ªßa m√¨nh. ƒê·ª´ng ƒë·ªìng √Ω qu√° d·ªÖ d√†ng.
                """
                response = model.generate_content(prompt)
                st.markdown(response.text)
                st.session_state.chat_history.append({"role": "assistant", "content": response.text})

# ================= TAB 4: L·ªäCH S·ª¨ (MEMORY) =================
with tab4:
    st.header("aaa Kho L∆∞u Tr·ªØ T√°c V·ª•")
    st.caption("L∆∞u tr·ªØ t·∫°m th·ªùi trong phi√™n l√†m vi·ªác n√†y. Refresh trang s·∫Ω m·∫•t.")
    
    if len(st.session_state.history) == 0:
        st.info("Ch∆∞a c√≥ d·ªØ li·ªáu l·ªãch s·ª≠.")
    else:
        for item in reversed(st.session_state.history):
            with st.expander(f"‚è∞ {item['time']} | {item['type']} | {item['title']}"):
                st.markdown(item['content'])
                st.download_button("T·∫£i v·ªÅ", item['content'], file_name=f"Log_{item['time']}.txt")
