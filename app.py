import streamlit as st
import google.generativeai as genai
import pandas as pd
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
from pypdf import PdfReader
from docx import Document
import numpy as np
import os
from bs4 import BeautifulSoup
import time

# --- 1. C·∫§U H√åNH ---
st.set_page_config(page_title="Mai Hanh Strategy (Final)", layout="wide", page_icon="üíé")
st.title("üíé The Mai Hanh Analyzer (Final & Clean)")

# L·∫•y Key t·ª´ Secrets
if 'GOOGLE_API_KEY' in st.secrets:
    API_KEY = st.secrets['GOOGLE_API_KEY']
    genai.configure(api_key=API_KEY)
else:
    st.warning("‚ö†Ô∏è L·ªói: Kh√¥ng t√¨m th·∫•y API Key trong Secrets. Vui l√≤ng ki·ªÉm tra l·∫°i c·∫•u h√¨nh Deployment.")
    st.stop()

# Ch·ªçn Model (2.5 Pro l√† ∆∞u ti√™n)
try:
    model = genai.GenerativeModel('gemini-2.5-pro') 
except:
    model = genai.GenerativeModel('gemini-2.5-flash')


# --- H√ÄM X·ª¨ L√ù D·ªÆ LI·ªÜU ---
@st.cache_resource
def load_models():
    return SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')

def doc_noi_dung_file(uploaded_file):
    if not uploaded_file: return ""
    ext = os.path.splitext(uploaded_file.name)[1].lower()
    try:
        if ext == '.pdf':
            reader = PdfReader(uploaded_file)
            return "\\n".join([page.extract_text() for page in reader.pages])
        elif ext == '.docx':
            doc = Document(uploaded_file)
            return "\\n".join([p.text for p in doc.paragraphs])
        elif ext in ['.txt', '.md']:
            return str(uploaded_file.read(), "utf-8")
        elif ext in ['.html', '.htm']:
            soup = BeautifulSoup(uploaded_file, 'html.parser')
            return soup.get_text()
    except: return ""
    return ""

# --- GIAO DI·ªÜN ---
with st.sidebar:
    st.header("1. K·∫øt N·ªëi Kho S√°ch")
    file_excel = st.file_uploader("Upload Book146.xlsx", type="xlsx")
    
    vec_model = None
    db_vec = None
    df = None
    
    if file_excel:
        try:
            df = pd.read_excel(file_excel).dropna(subset=['T√™n s√°ch'])
            vec_model = load_models()
            content = [f"{{r['T√™n s√°ch']}} {{r['C·∫¢M NH·∫¨N']}}" for i,r in df.iterrows()]
            db_vec = vec_model.encode(content)
            st.success(f"‚úÖ ƒê√£ n·∫°p {{len(df)}} cu·ªën s√°ch c≈©.")
        except: st.error("L·ªói file Excel")

st.header("2. Upload T√†i Li·ªáu (Ch·ªçn nhi·ªÅu file)")
uploaded_files = st.file_uploader(
    "K√©o th·∫£ c√°c file c·∫ßn ph√¢n t√≠ch v√†o ƒë√¢y", 
    type=["pdf","docx","txt","md","html"], 
    accept_multiple_files=True 
)

# N√öT B·∫§M CH√çNH
if st.button("üöÄ PH√ÇN T√çCH & T·ªîNG H·ª¢P CHI·∫æN L∆Ø·ª¢C", type="primary"):
    if not uploaded_files:
        st.warning("Ch∆∞a c√≥ file n√†o!")
    else:
        progress_bar = st.progress(0)
        total_files = len(uploaded_files)
        danh_sach_tom_tat = [] 

        st.subheader("üìù I. Ph√¢n T√≠ch Chi Ti·∫øt T·ª´ng T√†i Li·ªáu")
        
        for i, file_doc in enumerate(uploaded_files):
            with st.spinner(f"ƒêang x·ª≠ l√Ω file {{i+1}}/{{total_files}}: {{file_doc.name}}..."):
                text = doc_noi_dung_file(file_doc)
                do_dai = len(text)
                
                # --- 1. RAG (LI√äN K·∫æT) ---
                lien_ket = ""
                if file_excel and len(text) > 50:
                    try:
                        query_vec = vec_model.encode([text[:1000]])
                        scores = cosine_similarity(query_vec, db_vec)[0]
                        top = np.argsort(scores)[::-1][:3]
                        for idx in top:
                            if scores[idx] > 0.35:
                                lien_ket += f"- {{df.iloc[idx]['T√™n s√°ch']}}\\n"
                    except: pass
                
                # --- 2. C∆† CH·∫æ C·∫ÆT FILE AN TO√ÄN (FIX L·ªñI 429) ---
                text_to_send = text
                ghi_chu_cat = ""
                GIOI_HAN_KY_TU = 30000 
                
                if len(text) > GIOI_HAN_KY TU:
                    text_to_send = text[:15000] + "\\n...\\n" + text[-15000:]
                    ghi_chu_cat = "(ƒê√£ ph√¢n t√≠ch tr√™n Tr√≠ch ƒëo·∫°n ƒê·∫ßu v√† Cu·ªëi do gi·ªõi h·∫°n API)"
                
                # --- 3. G·ªåI API & X·ª¨ L√ù L·ªñI ---
                try:
                    prompt = f'''
                    Ph√¢n t√≠ch t√†i li·ªáu: '{{file_doc.name}}'.
                    Li√™n k·∫øt s√°ch c≈©: {{lien_ket}}
                    Y√äU C·∫¶U: 1. T√≥m t·∫Øt c·ªët l√µi. 2. Nh·∫≠n x√©t chi·ªÅu s√¢u. 3. Tr√≠ch d·∫´n c√¢u hay nh·∫•t.
                    N·ªôi dung: {{text_to_send}}
                    {ghi_chu_cat}
                    '''
                    res = model.generate_content(prompt)
                    res_text = res.text
                    
                except Exception as e:
                    res_text = f"‚ùå L·ªói AI: {{e}}.\\n\\n*M·∫πo: Vui l√≤ng ch·ªù 1 ph√∫t ho·∫∑c th·ª≠ l·∫°i file nh·ªè h∆°n.*"

                # HI·ªÇN TH·ªä V√Ä L∆ØU K·∫æT QU·∫¢
                danh_sach_tom_tat.append(f"=== T√ÄI LI·ªÜU {{i+1}}: {{file_doc.name}} ===\\n{{res_text}}\\n")
                
                with st.expander(f"üìÑ K·∫øt qu·∫£: {{file_doc.name}}", expanded=False):
                    st.markdown(res_text)
            
            progress_bar.progress((i + 1) / total_files)

        # --- GIAI ƒêO·∫†N 2: T·ªîNG H·ª¢P CHI·∫æN L∆Ø·ª¢C ---
        st.divider()
        st.header("üèÜ II. B√ÅO C√ÅO T·ªîNG QUAN CHI·∫æN L∆Ø·ª¢C")
        
        if len(danh_sach_tom_tat) > 0:
            with st.spinner("üß† ƒêang t·ªïng h·ª£p..."):
                du_lieu_tong_hop = "\\n".join(danh_sach_tom_tat)
                prompt_tong_hop = f'''
                B·∫°n l√† C·ªë v·∫•n Chi·∫øn l∆∞·ª£c. Vi·∫øt B√ÅO C√ÅO T·ªîNG H·ª¢P (SYNTHESIS) t·ª´ c√°c d·ªØ li·ªáu sau:
                {{du_lieu_tong_hop}}
                '''
                
                try:
                    res_tong_hop = model.generate_content(prompt_tong_hop)
                    st.success("ƒê√£ ho√†n th√†nh!")
                    st.markdown(res_tong_hop.text)
                    st.download_button("üíæ T·∫£i B√°o C√°o T·ªïng H·ª£p", res_tong_hop.text, file_name="Bao_Cao_Tong_Hop.txt")
                except:
                    st.error("L·ªói khi t·ªïng h·ª£p.")
"""

with open("app.py", "w", encoding='utf-8') as f:
    f.write(code_app)

# --- 3. CH·∫†Y NGROK (Kh·ªüi ƒë·ªông l·∫°i) ---
ngrok.set_auth_token(NGROK_TOKEN)
ngrok.kill()
public_url = ngrok.connect(8501).public_url
print(f"\nüëâ LINK VIP C·ª¶A CH·ªä ƒê√ÇY: {public_url}\n")

!streamlit run app.py
