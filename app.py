
import streamlit as st
import google.generativeai as genai
import pandas as pd
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
from pypdf import PdfReader
from docx import Document
from bs4 import BeautifulSoup
import numpy as np
import os

# --- C·∫§U H√åNH ---
st.set_page_config(page_title="Mai Hanh Strategy", layout="wide", page_icon="üíé")
st.title("üíé The Mai Hanh Analyzer (Cloud Version)")

# --- QU·∫¢N L√ù B·∫¢O M·∫¨T (SECRETS) ---
# Khi l√™n Cloud, API Key s·∫Ω ƒë∆∞·ª£c l·∫•y t·ª´ h·ªá th·ªëng b·∫£o m·∫≠t c·ªßa Streamlit
# Ch·ª© kh√¥ng d√°n c·ª©ng v√†o code ƒë·ªÉ tr√°nh b·ªã l·ªô
if 'GOOGLE_API_KEY' in st.secrets:
    api_key = st.secrets['GOOGLE_API_KEY']
else:
    api_key = st.sidebar.text_input("Nh·∫≠p Google API Key:", type="password")

if not api_key:
    st.warning("‚ö†Ô∏è Vui l√≤ng nh·∫≠p API Key ƒë·ªÉ ti·∫øp t·ª•c.")
    st.stop()

genai.configure(api_key=api_key)
model = genai.GenerativeModel('gemini-1.5-pro')

# --- H√ÄM X·ª¨ L√ù ---
@st.cache_resource
def load_models():
    return SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')

def doc_noi_dung_file(uploaded_file):
    if not uploaded_file: return ""
    ext = os.path.splitext(uploaded_file.name)[1].lower()
    try:
        if ext == '.pdf':
            reader = PdfReader(uploaded_file)
            return "\n".join([page.extract_text() for page in reader.pages])
        elif ext == '.docx':
            doc = Document(uploaded_file)
            return "\n".join([p.text for p in doc.paragraphs])
        elif ext in ['.txt', '.md']:
            return str(uploaded_file.read(), "utf-8")
        elif ext in ['.html', '.htm']:
            soup = BeautifulSoup(uploaded_file, 'html.parser')
            text = soup.get_text()
            return text
    except: return ""
    return ""

# --- GIAO DI·ªÜN ---
with st.sidebar:
    st.header("1. K·∫øt N·ªëi Kho S√°ch")
    file_excel = st.file_uploader("Upload Book146.xlsx", type="xlsx")
    
    vec_model = None
    db_vec = None
    df = None
    
    if file_excel:
        try:
            df = pd.read_csv(uploaded_excel).dropna(subset=['T√™n s√°ch'])
            vec_model = load_models()
            content = [f"{r['T√™n s√°ch']} {r['C·∫¢M NH·∫¨N']}" for i,r in df.iterrows()]
            db_vec = vec_model.encode(content)
            st.success(f"‚úÖ ƒê√£ n·∫°p {len(df)} cu·ªën s√°ch c≈©.")
        except: st.error("L·ªói file Excel")

st.header("2. Upload T√†i Li·ªáu (Ch·ªçn nhi·ªÅu file)")
uploaded_files = st.file_uploader(
    "K√©o th·∫£ c√°c file c·∫ßn ph√¢n t√≠ch v√†o ƒë√¢y", 
    type=["pdf","docx","txt","md","html"], 
    accept_multiple_files=True 
)

if st.button("üöÄ PH√ÇN T√çCH & T·ªîNG H·ª¢P CHI·∫æN L∆Ø·ª¢C", type="primary"):
    if not uploaded_files:
        st.warning("Ch∆∞a c√≥ file n√†o!")
    else:
        progress_bar = st.progress(0)
        total_files = len(uploaded_files)
        danh_sach_tom_tat = [] 

        st.subheader("üìù I. Ph√¢n T√≠ch Chi Ti·∫øt")
        
        for i, file_doc in enumerate(uploaded_files):
            with st.spinner(f"ƒêang ƒë·ªçc file {i+1}/{total_files}: {file_doc.name}..."):
                text = doc_noi_dung_file(file_doc)
                
                # RAG
                lien_ket = ""
                if file_excel and len(text) > 50:
                    try:
                        query_vec = vec_model.encode([text[:1000]])
                        scores = cosine_similarity(query_vec, db_vec)[0]
                        top = np.argsort(scores)[::-1][:3]
                        for idx in top:
                            if scores[idx] > 0.35:
                                lien_ket += f"- {df.iloc[idx]['T√™n s√°ch']}\n"
                    except: pass

                # Prompt
                prompt = f'''
                Ph√¢n t√≠ch t√†i li·ªáu: '{file_doc.name}'.
                Li√™n k·∫øt s√°ch c≈©: {lien_ket}
                Y√™u c·∫ßu: T√≥m t·∫Øt, Nh·∫≠n x√©t s√¢u s·∫Øc, Tr√≠ch d·∫´n hay.
                N·ªôi dung: {text}
                '''
                
                try:
                    res = model.generate_content(prompt)
                    danh_sach_tom_tat.append(f"=== T√ÄI LI·ªÜU {i+1}: {file_doc.name} ===\n{res.text}\n")
                    with st.expander(f"üìÑ K·∫øt qu·∫£: {file_doc.name}", expanded=False):
                        st.markdown(res.text)
                except Exception as e:
                    st.error(f"L·ªói AI: {e}")
            
            progress_bar.progress((i + 1) / total_files)

        st.divider()
        st.header("üèÜ II. B√ÅO C√ÅO T·ªîNG QUAN CHI·∫æN L∆Ø·ª¢C")
        
        if len(danh_sach_tom_tat) > 0:
            with st.spinner("üß† ƒêang t·ªïng h·ª£p..."):
                du_lieu_tong_hop = "\n".join(danh_sach_tom_tat)
                prompt_tong_hop = f'''
                B·∫°n l√† C·ªë v·∫•n Chi·∫øn l∆∞·ª£c. Vi·∫øt B√ÅO C√ÅO T·ªîNG H·ª¢P (SYNTHESIS) t·ª´:
                {du_lieu_tong_hop}
                '''
                try:
                    res_tong_hop = model.generate_content(prompt_tong_hop)
                    st.success("ƒê√£ ho√†n th√†nh!")
                    st.markdown(res_tong_hop.text)
                except: st.error("L·ªói t·ªïng h·ª£p.")
