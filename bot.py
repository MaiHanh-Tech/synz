import logging
import os
from telegram import Update
from telegram.ext import ApplicationBuilder, ContextTypes, CommandHandler, MessageHandler, filters
import google.generativeai as genai

# --- C·∫§U H√åNH ---
TELEGRAM_TOKEN = os.environ.get("TELEGRAM_TOKEN")
GOOGLE_API_KEY = os.environ.get("GOOGLE_API_KEY")

logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)

# --- K·∫æT N·ªêI 2 B·ªò N√ÉO (FLASH & PRO) ---
if GOOGLE_API_KEY:
    genai.configure(api_key=GOOGLE_API_KEY)
    model_flash = genai.GenerativeModel('gemini-2.5-flash') # Chat th∆∞·ªùng
    model_pro = genai.GenerativeModel('gemini-2.5-pro')     # Chat s√¢u (/g)
else:
    print("‚ö†Ô∏è C·∫¢NH B√ÅO: Ch∆∞a th·∫•y GOOGLE_API_KEY!")

# L∆∞u l·ªãch s·ª≠ chat cho Flash
chat_history = {}

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    msg = """
    üöÄ **VietMaiAI Lite (Si√™u T·ªëc)** ƒë√£ s·∫µn s√†ng!
    
    - Chat th∆∞·ªùng: D√πng Gemini Flash (Ph·∫£n h·ªìi t·ª©c th√¨).
    - Chat s√¢u: G√µ `/g <c√¢u h·ªèi>` d√πng Gemini Pro.
    
    *Phi√™n b·∫£n n√†y ƒë√£ b·ªè Voice ƒë·ªÉ ƒë·∫£m b·∫£o t·ªëc ƒë·ªô cao nh·∫•t.*
    """
    await update.message.reply_text(msg)

async def chat_with_ai(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_text = update.message.text
    chat_id = update.effective_chat.id
    
    print(f"üì© Nh·∫≠n tin: {user_text}") 
    # B√°o "ƒêang g√µ..." ngay l·∫≠p t·ª©c ƒë·ªÉ Ch·ªã bi·∫øt bot c√≤n s·ªëng
    await context.bot.send_chat_action(chat_id=chat_id, action='typing')

    try:
        ai_reply = ""

        # --- CH·∫æ ƒê·ªò CHUY√äN GIA (/g) ---
        if user_text.lower().startswith("/g "):
            real_prompt = user_text[3:].strip()
            # D√πng Pro, kh√¥ng c·∫ßn nh·ªõ l·ªãch s·ª≠ ƒë·ªÉ t·∫≠p trung ph√¢n t√≠ch
            response = model_pro.generate_content(real_prompt)
            ai_reply = f"üß† **[PRO ANALYSIS]**\n{response.text}"

        # --- CH·∫æ ƒê·ªò TH∆Ø·ªúNG (FLASH) ---
        else:
            if chat_id not in chat_history:
                chat_history[chat_id] = model_flash.start_chat(history=[
                    {"role": "user", "parts": "B·∫°n l√† tr·ª£ l√Ω ·∫£o th√¥ng minh, tr·∫£ l·ªùi ng·∫Øn g·ªçn, s√∫c t√≠ch v√† th√¢n thi·ªán."},
                    {"role": "model", "parts": "D·∫°, em nghe ƒë√¢y ·∫°!"}
                ])
            chat = chat_history[chat_id]
            
            response = chat.send_message(user_text)
            ai_reply = response.text

        # --- G·ª¨I K·∫æT QU·∫¢ NGAY L·∫¨P T·ª®C ---
        # Chia nh·ªè n·∫øu tin qu√° d√†i (Telegram gi·ªõi h·∫°n)
        if len(ai_reply) > 4000:
            for x in range(0, len(ai_reply), 4000):
                await update.message.reply_text(ai_reply[x:x+4000])
        else:
            await update.message.reply_text(ai_reply)
            
    except Exception as e:
        print(f"L·ªói: {e}")
        await update.message.reply_text(f"‚ö†Ô∏è M·∫°ng ch·∫≠p ch·ªùn, ch·ªã h·ªèi l·∫°i gi√∫p em nh√©! ({e})")

# --- CH·∫†Y BOT ---
if __name__ == '__main__':
    if not TELEGRAM_TOKEN:
        print("‚ùå L·ªñI: Ch∆∞a c√≥ TELEGRAM_TOKEN!")
    else:
        print("üöÄ VietMaiAI Lite ƒëang kh·ªüi ƒë·ªông...")
        application = ApplicationBuilder().token(TELEGRAM_TOKEN).build()
        application.add_handler(CommandHandler('start', start))
        application.add_handler(MessageHandler(filters.TEXT & (~filters.COMMAND), chat_with_ai))
        application.run_polling()
