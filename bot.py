import logging
import os
import asyncio
from telegram import Update
from telegram.ext import ApplicationBuilder, ContextTypes, CommandHandler, MessageHandler, filters
import google.generativeai as genai
from http.server import BaseHTTPRequestHandler, HTTPServer
import threading # ƒê·ªÉ ch·∫°y Web v√† Bot song song

# --- C·∫§U H√åNH ---
TELEGRAM_TOKEN = os.environ.get("TELEGRAM_TOKEN")
GOOGLE_API_KEY = os.environ.get("GOOGLE_API_KEY")

logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)

# --- K·∫æT N·ªêI B·ªò N√ÉO ---
if GOOGLE_API_KEY:
    genai.configure(api_key=GOOGLE_API_KEY)
    model_flash = genai.GenerativeModel('gemini-2.5-pro')
    model_pro = genai.GenerativeModel('gemini-2.5-pro')
else:
    print("‚ö†Ô∏è CH√ö √ù: Ch∆∞a th·∫•y GOOGLE_API_KEY!")

chat_history = {}

# --- [M·ªöI] 1. H√ÄM X·ª¨ L√ù WEB (ƒê√ÅNH L·ª™A RENDER) ---
class HealthCheckHandler(BaseHTTPRequestHandler):
    """X·ª≠ l√Ω y√™u c·∫ßu HTTP ƒë∆°n gi·∫£n (ƒê√°nh l·ª´a Render)"""
    def do_GET(self):
        self.send_response(200)
        self.send_header('Content-type', 'text/html')
        self.end_headers()
        self.wfile.write(b"Bot is alive!")

def run_web_server():
    """Ch·∫°y Server Web gi·∫£ ƒë·ªÉ gi·ªØ Bot s·ªëng"""
    # Render y√™u c·∫ßu d√πng c·ªïng PORT l·∫•y t·ª´ Environment Variable
    PORT = int(os.environ.get("PORT", 8080)) 
    server = HTTPServer(('', PORT), HealthCheckHandler)
    print(f"üåê Web Server gi·∫£ ch·∫°y tr√™n c·ªïng {PORT} (Gi·ªØ Bot s·ªëng)...")
    server.serve_forever()

# --- 2. H√ÄM X·ª¨ L√ù BOT TELEGRAM (GI·ªÆ NGUY√äN LOGIC C≈®) ---
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("üöÄ VietMaiAI ƒë√£ s·ªëng l·∫°i! (Hybrid Mode)")

async def chat_with_ai(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_text = update.message.text
    chat_id = update.effective_chat.id
    await context.bot.send_chat_action(chat_id=chat_id, action='typing')
    
    # Logic Gemini (Flash/Pro) gi·ªØ nguy√™n nh∆∞ c≈©
    # ... (Ch√®n logic Gemini Dual-Core v√†o ƒë√¢y) ...
    try:
        if user_text.lower().startswith("/g "):
            # Logic PRO
            real_prompt = user_text[3:].strip()
            response = model_pro.generate_content(real_prompt)
            ai_reply = f"üß† **[PRO]**\n{response.text}"
        else:
            # Logic FLASH
            if chat_id not in chat_history:
                chat_history[chat_id] = model_flash.start_chat(history=[])
            response = chat_history[chat_id].send_message(user_text)
            ai_reply = response.text
            
        # G·ª≠i Text
        await update.message.reply_text(ai_reply)
        
    except Exception as e:
        await update.message.reply_text(f"‚ö†Ô∏è L·ªói x·ª≠ l√Ω: {str(e)}")

# --- 3. H√ÄM CH·∫†Y CH√çNH (K·∫æT H·ª¢P C·∫¢ 2) ---
if __name__ == '__main__':
    if not TELEGRAM_TOKEN:
        print("‚ùå L·ªñI: Ch∆∞a c√≥ TELEGRAM_TOKEN!")
    else:
        # A. CH·∫†Y WEB SERVER (THREAD RI√äNG)
        web_thread = threading.Thread(target=run_web_server)
        web_thread.start()
        
        # B. CH·∫†Y TELEGRAM BOT (THREAD CH√çNH)
        print("ü§ñ B·∫Øt ƒë·∫ßu Polling Telegram...")
        application = ApplicationBuilder().token(TELEGRAM_TOKEN).build()
        application.add_handler(CommandHandler('start', start))
        application.add_handler(MessageHandler(filters.TEXT & (~filters.COMMAND), chat_with_ai))
        application.run_polling()
