import streamlit as st
import google.generativeai as genai
from openai import OpenAI
import time

# Exceptions
from google.api_core.exceptions import ResourceExhausted as GeminiResourceExhausted
from google.api_core.exceptions import ServiceUnavailable as GeminiServiceUnavailable, InternalServerError as GeminiInternalError
from openai import RateLimitError, APIError, AuthenticationError, Timeout

class AI_Core:
    def __init__(self):
        self.status_container = st.container()
        self.status_message = st.empty()
        self.grok_ready = False
        self.gemini_ready = False
        self.deepseek_ready = False
        self.grok_client = None
        self.deepseek_client = None

        # ‚úÖ TIMEOUT M·∫∂C ƒê·ªäNH
        self.DEFAULT_TIMEOUT = 30  # 30 gi√¢y max
        
        # 1. DEEPSEEK
        try:
            if "deepseek" in st.secrets and "api_key" in st.secrets["deepseek"]:
                self.deepseek_client = OpenAI(
                    api_key=st.secrets["deepseek"]["api_key"],
                    base_url="https://api.deepseek.com/v1",
                    timeout=self.DEFAULT_TIMEOUT  # ‚úÖ TH√äM TIMEOUT
                )
                self.deepseek_ready = True
        except Exception:
            pass
        
        # 2. GEMINI
        try:
            if "api_keys" in st.secrets and "gemini_api_key" in st.secrets["api_keys"]:
                genai.configure(api_key=st.secrets["api_keys"]["gemini_api_key"])
                self.safety_settings = [
                    {"category": c, "threshold": "BLOCK_NONE"} for c in [
                        "HARM_CATEGORY_HARASSMENT",
                        "HARM_CATEGORY_HATE_SPEECH",
                        "HARM_CATEGORY_SEXUALLY_EXPLICIT",
                        "HARM_CATEGORY_DANGEROUS_CONTENT"
                    ]
                ]
                self.gen_config = genai.GenerationConfig(
                    temperature=0.7,  # ‚úÖ GI·∫¢M t·ª´ 0.8 ‚Üí 0.7 (√≠t random h∆°n)
                    max_output_tokens=2000,  # ‚úÖ GI·∫¢M t·ª´ 7000 ‚Üí 2000 (tranh bi·ªán ng·∫Øn g·ªçn)
                    top_p=0.9,  # ‚úÖ GI·∫¢M t·ª´ 0.95 ‚Üí 0.9
                    top_k=40
                )
                self.gemini_ready = True
        except Exception:
            pass

        # 3. GROK
        try:
            if "xai" in st.secrets and "api_key" in st.secrets["xai"]:
                self.grok_client = OpenAI(
                    api_key=st.secrets["xai"]["api_key"],
                    base_url="https://api.x.ai/v1",
                    timeout=self.DEFAULT_TIMEOUT  # ‚úÖ TH√äM TIMEOUT
                )
                self.grok_ready = True
        except Exception:
            pass

        # Status
        with self.status_container:
            status_parts = []
            if self.deepseek_ready: status_parts.append("üü£ DeepSeek")
            if self.gemini_ready: status_parts.append("üü° Gemini")
            if self.grok_ready: status_parts.append("üü¢ Grok")
            if not status_parts:
                st.error("üî¥ Kh√¥ng c√≥ API n√†o s·∫µn s√†ng")
            else:
                st.caption(f"**AI Engine:** {' ‚Üí '.join(status_parts)}")

    def _deepseek_generate(self, prompt, system_instruction=None, max_tokens=2000):
        """‚úÖ S·ª¨A: Th√™m timeout, gi·∫£m max_tokens, b·ªè sleep d√†i"""
        if not self.deepseek_ready: 
            return None
        
        models = ["deepseek-chat"]  # ‚úÖ B·ªé reasoner (ch·∫≠m + ƒë·∫Øt)
        messages = [{"role": "user", "content": prompt}]
        if system_instruction:
            messages.insert(0, {"role": "system", "content": system_instruction})

        for model in models:
            try:
                resp = self.deepseek_client.chat.completions.create(
                    model=model,
                    messages=messages,
                    temperature=0.7,  # ‚úÖ GI·∫¢M
                    max_tokens=max_tokens,  # ‚úÖ ƒê·ªòNG
                    timeout=self.DEFAULT_TIMEOUT  # ‚úÖ TH√äM
                )
                return resp.choices[0].message.content.strip()
            except Timeout:
                # ‚úÖ Timeout ‚Üí B·ªè qua model n√†y
                continue
            except (RateLimitError, APIError):
                time.sleep(2)  # ‚úÖ GI·∫¢M t·ª´ 5s ‚Üí 2s
                continue
            except Exception:
                continue
        return None

    def _gemini_generate(self, prompt, model_type="flash", system_instruction=None):
        """‚úÖ GI·ªÆ NGUY√äN nh∆∞ng th√™m timeout logic"""
        if not self.gemini_ready: 
            return None
        
        valid_models = {
            "flash": "gemini-2.0-flash-exp",
            "pro": "gemini-2.0-flash-exp"  # ‚úÖ D√πng flash cho c·∫£ 2 (nhanh h∆°n)
        }
        model_name = valid_models.get(model_type, "gemini-2.0-flash-exp")

        try:
            model = genai.GenerativeModel(
                model_name=model_name,
                safety_settings=self.safety_settings,
                generation_config=self.gen_config,
                system_instruction=system_instruction
            )
            # ‚úÖ TH√äM: Gemini kh√¥ng c√≥ timeout param, d√πng try-except
            response = model.generate_content(prompt)
            if response and response.text:
                return response.text.strip()
            return None
        except (GeminiResourceExhausted, GeminiServiceUnavailable, GeminiInternalError):
            return None
        except Exception:
            return None

    def _grok_generate(self, prompt, system_instruction=None, max_tokens=2000):
        """‚úÖ S·ª¨A: Th√™m timeout, gi·∫£m max_tokens"""
        if not self.grok_ready: 
            return None
        
        models = ["grok-beta"]  # ‚úÖ Ch·ªâ d√πng 1 model (nhanh h∆°n)
        messages = [{"role": "user", "content": prompt}]
        if system_instruction:
            messages.insert(0, {"role": "system", "content": system_instruction})

        for model in models:
            try:
                resp = self.grok_client.chat.completions.create(
                    model=model,
                    messages=messages,
                    temperature=0.7,
                    max_tokens=max_tokens,
                    timeout=self.DEFAULT_TIMEOUT  # ‚úÖ TH√äM
                )
                return resp.choices[0].message.content.strip()
            except Timeout:
                continue
            except (RateLimitError, APIError):
                time.sleep(2)  # ‚úÖ GI·∫¢M t·ª´ 5s ‚Üí 2s
                continue
            except Exception:
                continue
        return None

    def generate(self, prompt, model_type="pro", system_instruction=None, max_tokens=2000):
        """
        ‚úÖ CHI·∫æN L∆Ø·ª¢C M·ªöI: Gemini FIRST (nhanh nh·∫•t)
        Gemini ‚Üí DeepSeek ‚Üí Grok
        """
        self.status_message.info("ü§ñ ƒêang g·ªçi AI...")

        # ‚úÖ 1. GEMINI FIRST (Nhanh nh·∫•t)
        if self.gemini_ready:
            result = self._gemini_generate(prompt, model_type, system_instruction)
            if result:
                self.status_message.success("‚ö° Gemini")
                return result
        
        # ‚úÖ 2. DEEPSEEK (N·∫øu Gemini fail)
        if self.deepseek_ready:
            result = self._deepseek_generate(prompt, system_instruction, max_tokens)
            if result:
                self.status_message.success("üí∞ DeepSeek")
                return result

        # ‚úÖ 3. GROK (Cu·ªëi c√πng)
        if self.grok_ready:
            result = self._grok_generate(prompt, system_instruction, max_tokens)
            if result:
                self.status_message.success("üéØ Grok")
                return result
                
        self.status_message.error("‚ö†Ô∏è T·∫•t c·∫£ API b·∫≠n")
        return "‚ö†Ô∏è H·ªá th·ªëng b·∫≠n. Th·ª≠ l·∫°i sau!"

    @staticmethod
    @st.cache_data(ttl=3600)
    def analyze_static(text, instruction):
        """‚úÖ RAG d√πng Gemini (c√≥ cache, nhanh)"""
        try:
            # ‚úÖ ∆Øu ti√™n Gemini cho RAG (c√≥ cache)
            if "api_keys" in st.secrets and "gemini_api_key" in st.secrets["api_keys"]:
                genai.configure(api_key=st.secrets["api_keys"]["gemini_api_key"])
                model = genai.GenerativeModel("gemini-2.0-flash-exp")
                text = text[:150000]  # ‚úÖ Gemini ch·ªãu context d√†i
                response = model.generate_content(f"{instruction}\n\n{text}")
                if response and response.text:
                    return response.text.strip()
            
            # Fallback DeepSeek
            if "deepseek" in st.secrets:
                client = OpenAI(
                    api_key=st.secrets["deepseek"]["api_key"],
                    base_url="https://api.deepseek.com/v1",
                    timeout=60
                )
                text = text[:180000]
                resp = client.chat.completions.create(
                    model="deepseek-chat",
                    messages=[
                        {"role": "system", "content": instruction},
                        {"role": "user", "content": text}
                    ],
                    max_tokens=4000,
                    temperature=0.3
                )
                return resp.choices[0].message.content.strip()
                
            return "‚ùå Kh√¥ng c√≥ API kh·∫£ d·ª•ng"
        except Exception as e:
            return f"‚ùå RAG l·ªói: {str(e)[:150]}"
