
import streamlit as st
import google.generativeai as genai
from openai import OpenAI
import time

# Exceptions ƒë√∫ng chu·∫©n 2026
from google.api_core.exceptions import ResourceExhausted as GeminiResourceExhausted
from google.api_core.exceptions import ServiceUnavailable as GeminiServiceUnavailable, InternalServerError as GeminiInternalError
from openai import RateLimitError, APIError, OpenAIError  # ‚úÖ S·ª¨A: Import ƒë√∫ng

class AI_Core:
    def __init__(self):
        self.status_container = st.container()
        self.status_message = st.empty()  # ‚úÖ TH√äM: Status ƒë·ªông
        self.grok_ready = False
        self.gemini_ready = False
        self.deepseek_ready = False
        self.grok_client = None
        self.deepseek_client = None

        # 1. GROK (xAI) - ∆Øu ti√™n #1
        try:
            if "xai" in st.secrets and "api_key" in st.secrets["xai"]:
                self.grok_client = OpenAI(
                    api_key=st.secrets["xai"]["api_key"],
                    base_url="https://api.x.ai/v1"
                )
                self.grok_ready = True
        except Exception:
            pass  # Silent fail

        # 2. GEMINI - Backup ch·∫•t l∆∞·ª£ng
        try:
            if "api_keys" in st.secrets and "gemini_api_key" in st.secrets["api_keys"]:
                genai.configure(api_key=st.secrets["api_keys"]["gemini_api_key"])
                self.safety_settings = [
                    {"category": c, "threshold": "BLOCK_NONE"} for c in [
                        "HARM_CATEGORY_HARASSMENT",
                        "HARM_CATEGORY_HATE_SPEECH", 
                        "HARM_CATEGORY_SEXUALLY_EXPLICIT",
                        "HARM_CATEGORY_DANGEROUS_CONTENT"
                    ]
                ]
                self.gen_config = genai.GenerationConfig(
                    temperature=0.8, max_output_tokens=7000, top_p=0.95, top_k=40
                )
                self.gemini_ready = True
        except Exception:
            pass  # Silent fail

        # 3. DEEPSEEK FREE - C·ª©u c√°nh cu·ªëi
        try:
            if "deepseek" in st.secrets and "api_key" in st.secrets["deepseek"]:
                self.deepseek_client = OpenAI(
                    api_key=st.secrets["deepseek"]["api_key"],
                    base_url="https://api.deepseek.com/v1"
                )
                self.deepseek_ready = True
        except Exception:
            pass  # Silent fail

        # Status g·ªçn ƒë·∫πp ‚úÖ C·∫¢I TI·∫æN
        with self.status_container:
            status_parts = []
            if self.grok_ready: status_parts.append("üü¢ Grok")
            if self.gemini_ready: status_parts.append("üü° Gemini") 
            if self.deepseek_ready: status_parts.append("üü£ DeepSeek FREE")
            st.caption(f"**API Ready:** {' ‚Üí '.join(status_parts) or '‚ùå None'}")

    def _grok_generate(self, prompt, system_instruction=None):
        if not self.grok_ready: return None
        
        models = ["grok-4", "grok-beta", "grok-2"]  # ‚úÖ S·ª¨A: Model th·ª±c t·∫ø 2026
        messages = [{"role": "user", "content": prompt}]
        if system_instruction: messages.insert(0, {"role": "system", "content": system_instruction})

        for model in models:
            try:
                resp = self.grok_client.chat.completions.create(
                    model=model, messages=messages,
                    temperature=0.8, max_tokens=7000, top_p=0.95
                )
                return resp.choices[0].message.content.strip()
            except (RateLimitError, APIError, OpenAIError):
                time.sleep(3)
                continue
        return None

    def _gemini_generate(self, prompt, model_type="flash", system_instruction=None):
        if not self.gemini_ready: return None
        
        valid_models = {
            "flash": "gemini-2.5-flash",
            "pro": "gemini-2.5-pro"  
        }
        model_name = valid_models.get(model_type, "gemini-2.5-flash")

        try:
            model = genai.GenerativeModel(
                model_name=model_name,
                safety_settings=self.safety_settings,
                generation_config=self.gen_config,
                system_instruction=system_instruction
            )
            response = model.generate_content(prompt)
            return response.text.strip() if response and response.text else None
        except (GeminiResourceExhausted, GeminiServiceUnavailable, GeminiInternalError):
            return None

    def _deepseek_generate(self, prompt, system_instruction=None):
        if not self.deepseek_ready: return None
        
        models = ["deepseek-chat", "deepseek-reasoner"]  # Chu·∫©n
        messages = [{"role": "user", "content": prompt}]
        if system_instruction: messages.insert(0, {"role": "system", "content": system_instruction})

        for model in models:
            try:
                resp = self.deepseek_client.chat.completions.create(
                    model=model, messages=messages,
                    temperature=0.8, max_tokens=7000
                )
                return resp.choices[0].message.content.strip()
            except (RateLimitError, APIError, OpenAIError):
                time.sleep(3)
                continue
        return None

    def generate(self, prompt, model_type="pro", system_instruction=None):
        """GROK ‚Üí GEMINI ‚Üí DEEPSEEK - Auto fallback"""
        self.status_message.info("ü§ñ ƒêang g·ªçi AI...")
        
        # 1Ô∏è‚É£ GROK (Best)
        if self.grok_ready:
            result = self._grok_generate(prompt, system_instruction)
            if result:
                self.status_message.success("üéØ Grok ho√†n th√†nh")
                return result

        # 2Ô∏è‚É£ GEMINI  
        if self.gemini_ready:
            result = self._gemini_generate(prompt, model_type, system_instruction)
            if result:
                self.status_message.success("üîÑ Gemini ho√†n th√†nh")
                return result

        # 3Ô∏è‚É£ DEEPSEEK FREE
        if self.deepseek_ready:
            result = self._deepseek_generate(prompt, system_instruction)
            if result:
                self.status_message.success("üí∞ DeepSeek FREE ho√†n th√†nh")
                return result

        self.status_message.error("‚ö†Ô∏è T·∫•t c·∫£ API b·∫≠n. Th·ª≠ l·∫°i sau 2p!")
        return "‚ö†Ô∏è H·ªá th·ªëng b·∫≠n. Th·ª≠ l·∫°i sau 1-2 ph√∫t nh√© ch·ªã!"

    @staticmethod
    @st.cache_data(ttl=3600)
    def analyze_static(text, instruction):
        """RAG v·ªõi DeepSeek FREE (context 128k tokens)"""
        try:
            if "deepseek" not in st.secrets: 
                return "‚ùå C·∫ßn DeepSeek API cho RAG"
                
            client = OpenAI(
                api_key=st.secrets["deepseek"]["api_key"],
                base_url="https://api.deepseek.com/v1"
            )
            text = text[:180000]  # DeepSeek context d√†i
            
            resp = client.chat.completions.create(
                model="deepseek-chat",
                messages=[
                    {"role": "system", "content": instruction},
                    {"role": "user", "content": text}
                ],
                max_tokens=4000, temperature=0.3
            )
            return resp.choices[0].message.content.strip()
        except Exception as e:
            return f"‚ùå RAG l·ªói: {str(e)[:100]}"
